{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "068a3cb5",
   "metadata": {},
   "source": [
    "# Read data timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60894919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import libarchive\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3435a2dc-0ec7-4f6a-8766-053f8613e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526caf6c-747a-448a-9826-991492fee29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ccc7b4-ad4f-4661-812a-2b7b77c36910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) read all station names found in timeseries data, makes it faster to read this data later\n",
    "# dir1 = './202112/2021-12/'\n",
    "# files = sorted(os.listdir(dir1)) \n",
    "# start = '2021-12-01'\n",
    "# end = '2022-01-01'\n",
    "\n",
    "# create the csv file with header and columnnames\n",
    "# file_counter = 0\n",
    "# station_names = None\n",
    "# ds_cml = None # dataset to store cml data in\n",
    "# files_list = [] # raw data to store\n",
    "# for file in tqdm.tqdm(files):\n",
    "#     file_out = read_file(file) \n",
    "#     if file_out is not None:\n",
    "#         files_list.append( file_out )\n",
    "#         file_counter += 1\n",
    "        \n",
    "#     if file_counter > 500: # read data in cunchs\n",
    "#         df = pd.concat(files_list)['Link'] # only need link data\n",
    "#         if station_names is None:\n",
    "#             station_names = set(list(df))\n",
    "#         else:\n",
    "#             station_names.update(list(df))\n",
    "#         files_list = [] # reset container\n",
    "#         file_counter = 0 # reset counter\n",
    "        \n",
    "# with open('./2022-06_station_names.pickle', 'wb') as handle:\n",
    "#     pickle.dump(station_names, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2a11444-3261-48cd-a64c-b737f7cb021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "period = 'summer'\n",
    "if period == 'winter':\n",
    "    dir1 = '/home/erlend/offline_data/cml_telia/202112/2021-12/'\n",
    "    files = sorted(os.listdir(dir1)) \n",
    "    files = [ ff for ff in files if ff.split('.')[-2] == 'cpio'] # only use cpio files\n",
    "    start = '2021-12-01'\n",
    "    end = '2022-01-01'\n",
    "\n",
    "    with open('/home/erlend/offline_data/cml_telia/2021-12_station_names.pickle', 'rb') as handle:\n",
    "        station_names = list(pickle.load(handle))\n",
    "\n",
    "if period == 'summer':\n",
    "    dir1 = '/home/erlend/offline_data/cml_telia/202206/2022-06/'\n",
    "    files = sorted(os.listdir(dir1)) \n",
    "    files = [ ff for ff in files if ff.split('.')[-2] == 'cpio'] # only use cpio files\n",
    "    start = '2022-05-31'\n",
    "    end = '2022-07-01'\n",
    "\n",
    "    with open('/home/erlend/offline_data/cml_telia/2021-12_station_names.pickle', 'rb') as handle:\n",
    "        station_names = list(pickle.load(handle))\n",
    "\n",
    "# input files\n",
    "# dir1 = './202206/2022-06/'\n",
    "# files = sorted(os.listdir(dir1)) \n",
    "# start = '2022-05-31'\n",
    "# end = '2022-07-01'\n",
    "#with open('./2022-06_station_names.pickle', 'rb') as handle:\n",
    "#    station_names = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b65949bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function for reading files\n",
    "# def read_file(file): \n",
    "#     with libarchive.Archive(dir1 + file) as a:\n",
    "#         for entry in a: # move to first file\n",
    "#             if entry.pathname[:7] == 'mw_data':\n",
    "#                 data = BytesIO(a.read(size = entry.size))\n",
    "#                 df = pd.read_csv(data, sep=\",\",index_col=False)[['Timestamp', 'Link', 'TX', 'RX']]\n",
    "#                 df = df.rename(columns = {'Link': 'cml_id', 'TX': 'ts', 'RX': 'rs'})\n",
    "#                 df['time'] = pd.to_datetime(df['Timestamp'], format='%Y%m%d%H%M%S')\n",
    "#                 df = df.drop(columns = ['Timestamp'])\n",
    "                \n",
    "#                 # keep stations that are in metadata (remove the rest)\n",
    "#                 df = df[df['cml_id'].isin(station_names)]\n",
    "                \n",
    "#                 # create multi index for xarray transform\n",
    "#                 df = df.reset_index()\n",
    "#                 df = df.set_index(['cml_id', 'time']).sort_values([('time')], ascending=True)\n",
    "#                 return df.to_xarray().drop('index')\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "497f7deb-20b6-4dc1-a181-be4881846dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for file in files:\n",
    "#     with xr.open_dataset(\"concatenated.nc\", mode=\"w\") as ds:\n",
    "#         dataset = read_file(file)\n",
    "#         if dataset is not None:\n",
    "#             ds = xr.concat([ds, dataset], dim=\"time\")\n",
    "#             ds.to_netcdf(\"concatenated.nc\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfa448-f924-40d9-966e-32e4a653daac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88146bcb-5255-42b4-a789-dc38882c3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate the datasets using dask.array.concatenate\n",
    "# concatenated = xr.concat(datasets, dim=\"time\", data_vars=\"minimal\", coords=\"minimal\", compat=\"override\")\n",
    "\n",
    "# # Save the Dask-backed xarray Dataset to a new zarr file\n",
    "# concatenated.to_netcdf(\"concatenated.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db1280c-87da-4b1a-973b-4021be342698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4360596-12d6-4c8a-9c47-cd5d831bde05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbaddd10-1e65-41d1-a16e-2292e91395a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the datasets lazily as a Dask-backed xarray Dataset using xr.open_mfdataset\n",
    "# ds = xr.open_mfdataset(datasets, concat_dim=\"new_dimension_name\", combine=\"by_coords\")\n",
    "\n",
    "# # Save the dataset to zarr format\n",
    "# ds.to_zarr(\"dataset.zarr\", consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11fe42c-0ae2-4fe5-8ec0-5a9c06cafb61",
   "metadata": {},
   "source": [
    "### Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa73e3d9-6087-482b-aea6-c1f28fad29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating lengths\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # return: distance [km] between two points, assuming earth is a sphere\n",
    "    # https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude\n",
    "    R = 6373.0 # approximate radius of earth in km\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    \n",
    "    return abs(distance)\n",
    "\n",
    "# get metadata\n",
    "df = pd.read_csv('/home/erlend/offline_data/cml_telia/telia_metadata.csv').rename(columns={'sublink_id':'cml_id'}).set_index('cml_id')\n",
    "cmls = df.to_xarray()\n",
    "lengths = haversine(cmls.site_a_latitude.values, \n",
    "          cmls.site_a_longitude.values, \n",
    "          cmls.site_b_latitude.values, \n",
    "          cmls.site_b_longitude.values)\n",
    "\n",
    "cmls = cmls.assign_coords({'length': ('cml_id', lengths)})   \n",
    "cmls = cmls.assign_coords({'site_0_lat': ('cml_id', cmls.site_a_latitude.values)})   \n",
    "cmls = cmls.assign_coords({'site_0_lon': ('cml_id', cmls.site_a_longitude.values)})   \n",
    "cmls = cmls.assign_coords({'site_1_lat': ('cml_id', cmls.site_b_latitude.values)})   \n",
    "cmls = cmls.assign_coords({'site_1_lon': ('cml_id', cmls.site_b_longitude.values)})  \n",
    "cmls = cmls.assign_coords({'frequency': ('cml_id', cmls.frequency.values)})  \n",
    "cmls = cmls.assign_coords({'polarisation': ('cml_id', cmls.polarization.values)})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2422423d-16c5-4085-b136-4e74b5cb28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmls = cmls.drop_vars(['site_b_latitude', 'site_b_longitude', 'site_a_latitude', 'site_a_longitude', 'polarization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0527354-c8c0-4b9d-a398-156839446f23",
   "metadata": {},
   "source": [
    "### Sort metadata by name and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df8c417-c9b1-4a46-9e1a-4cc9bb067256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for reading files\n",
    "def read_file(file): \n",
    "    with libarchive.Archive(dir1 + file) as a:\n",
    "        list = []\n",
    "        for entry in a: # move to first file\n",
    "            if entry.pathname[:7] == 'mw_data':\n",
    "                data = BytesIO(a.read(size = entry.size))\n",
    "                df = pd.read_csv(data, sep=\",\",index_col=False)[['Timestamp', 'Link', 'TX', 'RX']]\n",
    "                df = df.rename(columns = {'Link': 'cml_id', 'TX': 'ts', 'RX': 'rs'})\n",
    "                df['time'] = pd.to_datetime(df['Timestamp'], format='%Y%m%d%H%M%S')\n",
    "                list.append(df.drop(columns = ['Timestamp']))\n",
    "\n",
    "        if len(list) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return pd.concat(list, ignore_index=True)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe33274-5c7b-4da3-9023-e7353fe05989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the csv file with header and columnnames\n",
    "file_counter = 0\n",
    "files_list = []\n",
    "ds_cml = None # dataset to store cml data in\n",
    "\n",
    "# create xarray object to store data in\n",
    "time_series = pd.date_range(start=start, end=end, freq='1T')\n",
    "sublink_id = np.array(sorted(list(station_names))) \n",
    "cmls_pairs = []\n",
    "for link_1 in sublink_id:\n",
    "    cmls_pairs.append([0, 0]) # dummy list for cleaner code\n",
    "    cmls_pairs[-1][0] = link_1\n",
    "    link1_name_site_a = link_1.split('.')[0]\n",
    "    link1_name_site_b = link_1.split('.')[1]\n",
    "\n",
    "    for link_2 in sublink_id: # go through the whole list from beginning\n",
    "        link2_name_site_a = link_2.split('.')[0]\n",
    "        link2_name_site_b = link_2.split('.')[1]\n",
    "        sita_a_is_site_b = link2_name_site_a == link1_name_site_b\n",
    "        sita_b_is_site_a = link1_name_site_a == link2_name_site_b\n",
    "        if sita_a_is_site_b and sita_b_is_site_a:\n",
    "            cmls_pairs[-1][1] = link_2\n",
    "\n",
    "\n",
    "# then remove duplicates\n",
    "drop_indx_pair = []\n",
    "\n",
    "# iterate the next n links\n",
    "for i, sublink1 in enumerate(cmls_pairs):\n",
    "    sublink1_a, sublink1_b = sublink1[0], sublink1[1]\n",
    "    \n",
    "    # search if sublink has a corresponding pair\n",
    "    sublink_has_pair = False\n",
    "    c = 0\n",
    "    while (c < len(cmls_pairs)) and (not sublink_has_pair):\n",
    "        sublink_check_a, sublink_check_b = cmls_pairs[c]\n",
    "        \n",
    "        # a fellow pair is alwas swiched\n",
    "        if (sublink1_a == sublink_check_b) and (sublink1_b == sublink_check_a):\n",
    "            sublink_has_pair = True\n",
    "        c +=1\n",
    "    c -= 1\n",
    "    \n",
    "    # if the sublink has pair\n",
    "    if sublink_has_pair:\n",
    "        if sorted([i, c]) not in drop_indx_pair:\n",
    "            drop_indx_pair.append(sorted([i, c]))\n",
    "    \n",
    "\n",
    "drop_indx = [drop_indx_pair[i][0] for i in range(len(drop_indx_pair))]\n",
    "sublink_id_pairs = np.array([cmls_pairs[i] for i in range(len(cmls_pairs)) if i not in drop_indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7f2194b-2b95-437e-803a-bcd4cb987633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We can get channel 2 name by just swiching the two stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf87b0e2-7764-4d78-8768-0b91d7d5f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for the two channels\n",
    "ds_cml2chl = xr.Dataset(\n",
    "    data_vars= dict(\n",
    "        rs=([\"cml_id\", 'sublink_id', 'time'], np.zeros([sublink_id_pairs.shape[0], 2, time_series.size]).astype('float32')*np.nan),\n",
    "        ts=([\"cml_id\", 'sublink_id', 'time'], np.zeros([sublink_id_pairs.shape[0], 2, time_series.size]).astype('float32')*np.nan), \n",
    "    ),\n",
    "    coords=dict(\n",
    "        cml_id = sublink_id_pairs[:, 0],\n",
    "        sublink_id = ['chl_1', 'chl_2'],\n",
    "        time = time_series,\n",
    "\n",
    "        length = ('cml_id', np.zeros(sublink_id_pairs[:, 0].shape[0])*np.nan),\n",
    "        site_0_lat = ('cml_id', np.zeros(sublink_id_pairs[:, 0].shape[0])*np.nan),\n",
    "        site_0_lon = ('cml_id', np.zeros(sublink_id_pairs[:, 0].shape[0])*np.nan),\n",
    "        site_1_lat = ('cml_id', np.zeros(sublink_id_pairs[:, 0].shape[0])*np.nan),\n",
    "        site_1_lon = ('cml_id', np.zeros(sublink_id_pairs[:, 0].shape[0])*np.nan),\n",
    "        frequency = ('cml_id', np.zeros(sublink_id_pairs[:, 0].shape[0])*np.nan),\n",
    "        polarisation = ('cml_id', (np.zeros(sublink_id_pairs[:, 0].shape[0])*np.nan).astype(str)),\n",
    "        \n",
    "    ),\n",
    ")\n",
    "\n",
    "# store the complete timeseries in this dataset (faster reading from files)\n",
    "ds_cml = xr.Dataset(\n",
    "    data_vars= dict(\n",
    "        rs=([\"cml_id\", 'time'], np.zeros([sublink_id.size, time_series.size]).astype('float32')*np.nan),\n",
    "        ts=([\"cml_id\", 'time'], np.zeros([sublink_id.size, time_series.size]).astype('float32')*np.nan), \n",
    "    ),\n",
    "    coords=dict(\n",
    "        cml_id = sublink_id,\n",
    "        time = time_series,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e70c0dff-4a3d-4910-925b-8d6fda7dc0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate xarray object with metadata where metadata exists\n",
    "cml_with_metadata = []\n",
    "\n",
    "for cml_id in ds_cml2chl.cml_id.values:\n",
    "    pop = False # wether to populate the dataset\n",
    "    try:\n",
    "        cml_metadata = cmls.sel(cml_id = cml_id)\n",
    "        pop = True\n",
    "\n",
    "    except:\n",
    "        # swich names, could work in theory but does not seem to be the case in the june set atleast! \n",
    "        cml_id2 = cml_id.split('.')\n",
    "        try:\n",
    "            cml_metadata = cmls.sel(cml_id = join([cml_id2[1],  cml_id2[0]]))\n",
    "            pop = True\n",
    "        except:\n",
    "            continue # nothing happened\n",
    "    \n",
    "    if pop:\n",
    "        cml_with_metadata.append(cml_id)\n",
    "        ds_cml2chl['length'].loc[{'cml_id': cml_id}] = cml_metadata.length.values\n",
    "        ds_cml2chl['site_0_lat'].loc[{'cml_id': cml_id}] = cml_metadata.site_0_lat.values\n",
    "        ds_cml2chl['site_0_lon'].loc[{'cml_id': cml_id}] = cml_metadata.site_0_lon.values\n",
    "        ds_cml2chl['site_1_lat'].loc[{'cml_id': cml_id}] = cml_metadata.site_1_lat.values\n",
    "        ds_cml2chl['site_1_lon'].loc[{'cml_id': cml_id}] = cml_metadata.site_1_lon.values\n",
    "        ds_cml2chl['frequency'].loc[{'cml_id': cml_id}] = cml_metadata.frequency.values\n",
    "        ds_cml2chl['polarisation'].loc[{'cml_id': cml_id}] = cml_metadata.polarisation.values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9320e088-2c8e-4223-aefa-2d125a5c56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop links without metadata (comment to keep the links)\n",
    "# ds_cml2chl = ds_cml2chl.sel(cml_id = cml_with_metadata)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e68c33-4cb1-405d-bfab-abfdd7896bdf",
   "metadata": {},
   "source": [
    "### Read timeseries from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a9b882c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 6712/6712 [48:47<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "file_counter = 0 # reset counter\n",
    "for file in tqdm.tqdm(files):\n",
    "    file_out = read_file(file)\n",
    "    if file_out is not None:\n",
    "        files_list.append( file_out )\n",
    "        file_counter += 1\n",
    "\n",
    "    if file_counter > 30: # read data in chunks\n",
    "        df = pd.concat(files_list)\n",
    "        files_list = [] # reset file container\n",
    "        file_conter = 0 # reset counter\n",
    "        \n",
    "        df.set_index(['time', 'cml_id'], inplace=True)\n",
    "        df = df.groupby(level=df.index.names).median() # when overlap use median\n",
    "\n",
    "        ds = df.to_xarray() # use the nearest value to the full minute\n",
    "        ds_rs = ds.rs.resample(time = '1T', skipna=True).nearest(tolerance = '0.5T').rename('rs')\n",
    "        ds_ts = ds.ts.resample(time = '1T', skipna=True).nearest(tolerance = '0.5T').rename('ts')\n",
    "        times_in_ds = ds_rs.time\n",
    "        links_in_ds = ds_rs.cml_id\n",
    "\n",
    "        # remove CMLs from timeseries chunk that is not present in allocated container ds_cml\n",
    "        in_list = []\n",
    "        for i in range(len(links_in_ds.values)):\n",
    "            if links_in_ds.values[i] in ds_cml.cml_id.values:\n",
    "                in_list.append(i)\n",
    "        links_in_ds = links_in_ds[in_list]\n",
    "        ds_rs = ds_rs.isel(cml_id = in_list)\n",
    "        ds_ts = ds_ts.isel(cml_id = in_list)        \n",
    "                \n",
    "        # Existing data from the data chunk\n",
    "        existing_data = ds_cml['rs'].loc[dict(time=times_in_ds, cml_id=links_in_ds)] \n",
    "\n",
    "        # where existing mean is nan we use the new data\n",
    "        # if existing and new has data, use existing, for further advancements use the closest, but that would require that we store the time\n",
    "        ds_cml['rs'].loc[dict(time=times_in_ds, cml_id=links_in_ds)] = xr.where(np.isnan(existing_data), ds_rs, existing_data)\n",
    "\n",
    "        # repeat for tx\n",
    "        existing_data = ds_cml['ts'].loc[dict(time=times_in_ds, cml_id=links_in_ds)] \n",
    "        ds_cml['ts'].loc[dict(time=times_in_ds, cml_id=links_in_ds)] = xr.where(np.isnan(existing_data), ds_ts, existing_data)\n",
    "        \n",
    "        # Then reset container and counter\n",
    "        files_list = [] \n",
    "        file_counter = 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51dc0be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 2777/2777 [00:04<00:00, 597.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# fill data from ds_cml into ds_cml2chl\n",
    "# strategy: for throught ds_cml2chl, name is chnl1, swich is channel 2:) \n",
    "for cml_id in tqdm.tqdm(ds_cml2chl.cml_id.values):\n",
    "\n",
    "    cml_id2 = cml_id.split('.')\n",
    "    try:\n",
    "        cml_data_ch1 = ds_cml.sel(cml_id = cml_id)\n",
    "        pop_ch1 = True\n",
    "        \n",
    "    except:\n",
    "        pop_ch1 = False\n",
    "        print('skip ', cml_id, ' .. something is wery wrong')\n",
    "        \n",
    "    try: # swiching possitions\n",
    "        cml_id_chl2 = '.'.join([cml_id2[1],  cml_id2[0]])\n",
    "        cml_data_ch2 = ds_cml.sel(cml_id = cml_id_chl2)\n",
    "        pop_ch2 = True\n",
    "    except:\n",
    "        # missing channel 2\n",
    "        pop_ch2 = False\n",
    "    \n",
    "    if pop_ch1 and pop_ch2: # both channels are present\n",
    "        ds_cml2chl['rs'].loc[{'cml_id': cml_id, 'sublink_id':'chl_1'}] = cml_data_ch1.rs.values\n",
    "        ds_cml2chl['ts'].loc[{'cml_id': cml_id, 'sublink_id':'chl_1'}] = cml_data_ch1.ts.values\n",
    "        ds_cml2chl['rs'].loc[{'cml_id': cml_id, 'sublink_id':'chl_2'}] = cml_data_ch2.rs.values\n",
    "        ds_cml2chl['ts'].loc[{'cml_id': cml_id, 'sublink_id':'chl_2'}] = cml_data_ch2.ts.values\n",
    "\n",
    "    # by construction channel 1 always has data\n",
    "    elif pop_ch1:\n",
    "        ds_cml2chl['rs'].loc[{'cml_id': cml_id, 'sublink_id':'chl_1'}] = cml_data_ch1.rs.values\n",
    "        ds_cml2chl['ts'].loc[{'cml_id': cml_id, 'sublink_id':'chl_1'}] = cml_data_ch1.ts.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd57e009-95ab-4e85-a1d9-3a5abb8c4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store it \n",
    "if period == 'winter':\n",
    "    ds_cml2chl.to_netcdf('/home/erlend/offline_data/cml_telia/cml_norway_2021-12.nc')\n",
    "if period == 'summer':\n",
    "    ds_cml2chl.to_netcdf('/home/erlend/offline_data/cml_telia/cml_norway_2022-06.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c055e5-c7e1-4b7a-80a2-c4a0848a8c24",
   "metadata": {},
   "source": [
    "# Eksport WKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2565c371-e426-450f-adc4-049404a94732",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'libarchive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibarchive\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'libarchive'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tqdm\n",
    "import pickle\n",
    "import libarchive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca8fc4a-9ce7-4442-bac7-7fb012e8eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/erlend/offline_data/cml_telia/meta_2022_June.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18719662-9d96-4973-a5bd-c96951908dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "linestring = ['LINESTRING(' + str(df['far_longitude'][i]) + ' ' + str(df['far_latitude'][i]) + \n",
    "              ',' + str(df['near_longitude'][i]) + ' ' + str(df['near_latitude'][i]) + ')' for i in range(df.link_id.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c1bfa67-7e81-45ab-8342-4bd01353e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(linestring)\n",
    "df_out['cml_id'] = df.link_id # add names, can also add more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4a61ce5-39e0-4cb8-a7e3-79f5299718de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('/home/erlend/offline_data/cml_telia/meta_2022_qgis', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d374cff-924d-4e37-8bb6-b4dfdea194ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cml2chl = xr.open_dataset('/home/erlend/offline_data/cml_telia/cml_norway_2021-12.nc').load()\n",
    "# drop if nan in coordinates ( then we dont know possition)\n",
    "cml_nan = np.isnan(ds_cml2chl.site_0_lat).values\n",
    "cml_keep = ds_cml2chl.cml_id.values[~cml_nan]\n",
    "ds_cml2chl = ds_cml2chl.sel(cml_id = cml_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9208989-b4b3-4204-9d3b-a4a10ca4ce38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linestring = ['LINESTRING(' + str(ds_cml2chl['site_1_lon'][i].values) + ' ' + str(ds_cml2chl['site_1_lat'][i].values) + \n",
    "              ',' + str(ds_cml2chl['site_0_lon'][i].values) + ' ' + str(ds_cml2chl['site_0_lat'][i].values) + ')' for i in range(ds_cml2chl.cml_id.size)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0980d1d-9b25-41a4-b265-455369ffa63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(linestring)\n",
    "df_out['cml_id'] = cml_keep # add names, can also add more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f4c7a18-f21a-499d-bb7f-f44ea8e5387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('/home/erlend/offline_data/cml_telia/meta_2022_June_qgis', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23433059-4eb0-4b60-8d99-7d2e14ae4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cml2chl = xr.open_dataset('/home/erlend/offline_data/cml_telia/cml_norway_2021-12.nc').load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6178f0ab-4015-40e4-8327-c4f75f49343f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;site_0_lat&#x27; ()&gt;\n",
       "array(154)</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'site_0_lat'</div></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-ff698995-deeb-4d21-b01e-a510b09a3618' class='xr-array-in' type='checkbox' checked><label for='section-ff698995-deeb-4d21-b01e-a510b09a3618' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>154</span></div><div class='xr-array-data'><pre>array(154)</pre></div></div></li><li class='xr-section-item'><input id='section-1a92e531-b0b9-4db4-8568-b9d16b7a9743' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-1a92e531-b0b9-4db4-8568-b9d16b7a9743' class='xr-section-summary'  title='Expand/collapse section'>Coordinates: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-d2b43f5f-866d-4487-b117-046b411b6754' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-d2b43f5f-866d-4487-b117-046b411b6754' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'site_0_lat' ()>\n",
       "array(154)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3np.isnan(ds_cml2chl.site_0_lat).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8bcc8-bcfb-431a-82dc-d5188f6eba6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
